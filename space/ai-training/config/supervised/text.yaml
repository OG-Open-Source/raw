# 系統資源設定
system:
  device: "auto"
  num_workers: 4
  pin_memory: true
  memory_limit: 0.8

# 模型架構參數
model:
  architecture_type: "transformer"
  input_size: 512
  hidden_size: 256
  output_size: 2
  reasoning_steps: 3
  attention_heads: 8
  dropout_rate: 0.2
  vocab_size: 30522  # BERT 的詞彙表大小

# 文本處理設定
text:
  tokenizer: "bert-base-chinese"
  max_length: 512
  padding: "max_length"
  truncation: true
  lowercase: true
  remove_punctuation: false
  special_tokens:
    pad: "[PAD]"
    unk: "[UNK]"
    cls: "[CLS]"
    sep: "[SEP]"

# 學習模式設定
learning_mode:
  type: "supervised"

# 資料處理
data:
  data_type: "text"
  train_path: "data/raw/train.json"
  val_path: "data/raw/val.json"
  test_path: "data/raw/test.json"
  format: "json"
  schema:
    text: "string"
    label: "int"
    metadata: "dict"

# 訓練參數
training:
  batch_size: 32
  learning_rate: 0.001
  epochs: 20
  optimizer: "adamw"
  use_scheduler: true
  early_stopping: true

# 混合精度訓練
mixed_precision:
  enabled: true
  dtype: "float16"

# 記憶體管理
memory:
  empty_cache_freq: 100  # 每處理多少樣本清理一次快取
  gradient_checkpointing: false
  max_grad_norm: 1.0